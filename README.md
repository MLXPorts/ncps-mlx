# üß† Neural Circuit Policies (NCPs) for Apple MLX

<div align="center">

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![MLX](https://img.shields.io/badge/MLX-Optimized-green.svg)](https://github.com/ml-explore/mlx)
[![Tests](https://github.com/SolaceHarmony/ncps-mlx/actions/workflows/python-test.yml/badge.svg)](https://github.com/SolaceHarmony/ncps-mlx/actions)
[![Apple Silicon](https://github.com/SolaceHarmony/ncps-mlx/actions/workflows/apple-silicon-tests.yml/badge.svg)](https://github.com/SolaceHarmony/ncps-mlx/actions)

[![GitHub stars](https://img.shields.io/github/stars/SolaceHarmony/ncps-mlx?style=social)](https://github.com/SolaceHarmony/ncps-mlx/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/SolaceHarmony/ncps-mlx?style=social)](https://github.com/SolaceHarmony/ncps-mlx/network/members)
[![GitHub issues](https://img.shields.io/github/issues/SolaceHarmony/ncps-mlx)](https://github.com/SolaceHarmony/ncps-mlx/issues)
[![GitHub release](https://img.shields.io/github/v/release/SolaceHarmony/ncps-mlx)](https://github.com/SolaceHarmony/ncps-mlx/releases)
[![Code style](https://img.shields.io/badge/code%20style-NCPSLint-brightgreen)](misc/emberlint.py)

**High-performance liquid neural networks powered by Apple's MLX framework**

[Features](#-features) ‚Ä¢
[Installation](#-installation) ‚Ä¢
[Quick Start](#-quick-start) ‚Ä¢
[Documentation](#-documentation) ‚Ä¢
[Examples](#-examples) ‚Ä¢
[Citation](#-citation)

<img src="misc/ncp_cnn.png" alt="NCP Architecture" width="600"/>

</div>

---

## üåü What are Neural Circuit Policies?

Neural Circuit Policies (NCPs) are a revolutionary class of neural networks inspired by the nervous system of the *C. elegans* worm. Unlike traditional neural networks, NCPs feature:

- **Liquid Time-Constant (LTC) Networks**: Neurons with adaptive time constants that can model complex temporal dynamics
- **Closed-form Continuous-time (CfC) Networks**: Fast, differentiable approximations of continuous-time systems
- **Interpretable Structure**: Sparse, wired connectivity patterns that enhance model transparency
- **Efficient Inference**: Continuous-time models that naturally handle irregular sampling and variable time steps

This MLX implementation brings the power of NCPs to Apple Silicon, delivering exceptional performance on M-series chips.

---

## üöÄ Features

### Core Capabilities

- ‚ö° **MLX-Optimized**: Leverages MLX's lazy evaluation and unified memory for blazing-fast performance on Apple Silicon
- üîÑ **Bidirectional Processing**: Process sequences forward and backward for enhanced context understanding
- ‚è±Ô∏è **Time-Aware Processing**: Native support for irregular time steps and continuous-time dynamics
- üß© **Modular Architecture**: Extensible base classes and mixins for easy customization
- üéØ **Multiple Model Types**: CfC, LTC, CTRNN, and CT-GRU implementations
- ÔøΩÔøΩ **Research-Ready**: Faithful implementations of published architectures

### Model Zoo

| Model | Description | Use Case |
|-------|-------------|----------|
| **CfC** | Closed-form Continuous-time RNN | Fast, general-purpose sequence modeling |
| **LTC** | Liquid Time-Constant Network | Complex temporal patterns, irregular sampling |
| **ELTC** | Enhanced LTC with ODE solvers | High-precision continuous dynamics |
| **CTRNN** | Continuous-Time RNN | Classic continuous-time modeling |
| **CT-GRU** | Continuous-Time GRU | Gated continuous-time processing |

---

## üì¶ Installation

### From PyPI (Coming Soon)

\`\`\`bash
pip install ncps-mlx
\`\`\`

### From Source

\`\`\`bash
git clone https://github.com/SolaceHarmony/ncps-mlx.git
cd ncps-mlx
pip install -e .
\`\`\`

### Optional Dependencies

\`\`\`bash
# For visualization features
pip install ncps-mlx[viz]

# For development
pip install ncps-mlx[dev]

# Everything
pip install ncps-mlx[all]
\`\`\`

### Requirements

- Python 3.8+
- MLX >= 0.1.0
- NumPy >= 1.19.2

---

## üéØ Quick Start

### Basic CfC Model

\`\`\`python
import mlx.core as mx
from ncps.mlx import CfC

# Create a CfC model
model = CfC(
    input_size=10,
    hidden_size=32,
    num_layers=2,
    return_sequences=True
)

# Process a sequence
x = mx.random.normal((16, 20, 10)) # e.g. batch_size=16, seq_length=20, input_size=10
outputs, states = model(x)

print(f"Output shape: {outputs.shape}")  # (seq_length, hidden_size)
\`\`\`

### Bidirectional Processing

\`\`\`python
# Enable bidirectional processing for better context
model = CfC(
    input_size=10,
    hidden_size=32,
    bidirectional=True,  # Process forward and backward
    merge_mode="concat"   # Concatenate outputs
)

outputs, states = model(x)
print(f"Bidirectional output: {outputs.shape}")  # (seq_length, 64)
\`\`\`

### Time-Aware LTC

\`\`\`python
from ncps.mlx import LTC

# Create time-aware model
model = LTC(
    input_size=10,
    hidden_size=32,
    num_layers=1
)

# Variable time steps (e.g., irregular sampling)
time_delta = mx.array([0.1, 0.15, 0.08, ...])  # Different Œît for each step

# Process with time awareness
outputs, states = model(x, time_delta=time_delta)
\`\`\`

### Custom Wirings

\`\`\`python
from ncps.mlx import LTC
from ncps.mlx.wirings import FullyConnected, Random

# Fully connected wiring
wiring = FullyConnected(units=32, output_dim=10)
wiring.build(input_dim=20)

# Or sparse random wiring (more efficient, interpretable)
wiring = Random(units=32, output_dim=10, sparsity_level=0.5)
wiring.build(input_dim=20)

# Use with LTC cell
from ncps.mlx import LTCCell
cell = LTCCell(wiring=wiring)
\`\`\`

### Save and Load Models

\`\`\`python
from ncps.mlx import save_model, load_model

# Train your model
# ...

# Save
save_model(model, "my_ncp_model.npz")

# Load later
model = CfC(input_size=10, hidden_size=32)
load_model(model, "my_ncp_model.npz")
\`\`\`

---

## üìà Project Stats

<div align="center">

![GitHub commit activity](https://img.shields.io/github/commit-activity/m/SolaceHarmony/ncps-mlx)
![GitHub last commit](https://img.shields.io/github/last-commit/SolaceHarmony/ncps-mlx)
![GitHub code size](https://img.shields.io/github/languages/code-size/SolaceHarmony/ncps-mlx)
![GitHub repo size](https://img.shields.io/github/repo-size/SolaceHarmony/ncps-mlx)

</div>

### Recent Activity

- ‚úÖ **v2.0.0** - Complete MLX implementation with all model types
- ‚úÖ **171 commits** - Continuous improvements and optimizations
- üîß **Active development** - Regular updates and bug fixes
- üß™ **CI/CD** - Automated testing on Apple Silicon and Linux

---

## üìö Documentation

### Core Documentation

- **[API Reference](docs/api/)**: Complete API documentation
- **[Examples](examples/)**: curated MLX scripts and interactive notebooks
- **[Architecture Guide](docs/architecture.md)**: Deep dive into the implementation

### Key Concepts

#### Liquid Time-Constant Networks

LTC networks model neurons with adaptive time constants:

\`\`\`
œÑ·µ¢(t) = œÉ(A‚Çìx(t) + A‚Çïh(t) + b)  # Time constant depends on input and state
dh/dt = -h(t)/œÑ(t) + f(W‚Çìx(t) + W‚Çïh(t))  # Continuous-time dynamics
\`\`\`

This allows the network to dynamically adjust its temporal responsiveness based on the input characteristics.

#### Closed-form Continuous-time (CfC)

CfC networks provide a fast, closed-form solution to the ODE:

\`\`\`
h(t+Œît) = (1 - exp(-Œît/œÑ)) * f(x, h) + exp(-Œît/œÑ) * h(t)
\`\`\`

This eliminates expensive ODE solving while maintaining continuous-time properties.

---

## üí° Examples

### Time Series Forecasting

\`\`\`python
import mlx.core as mx
from ncps.mlx import CfC

# Load your time series data
X_train, y_train = load_timeseries()

# Create model
model = CfC(input_size=features, hidden_size=64, num_layers=2)

# Simple training loop
for epoch in range(epochs):
    outputs, _ = model(X_train)
    loss = mx.mean((outputs - y_train) ** 2)
    # ... update weights
\`\`\`

### Sequential Decision Making

\`\`\`python
from ncps.mlx import LTC

# For robotics/control with irregular observations
model = LTC(
    input_size=sensor_dim,
    hidden_size=128,
    num_layers=1
)

# Process sensor readings with variable timestamps
action, state = model(observations, time_delta=timestamps)
\`\`\`

### More Examples

Check out our MLX-first [examples directory](examples/):

- `examples/mlx_cfc_regression.py` ‚Äì minimal regression loop using `nn.value_and_grad`, `optim.Adam`, and `Module.save_weights`.
- `examples/mlx_smnist_training.py` ‚Äì Sequential MNIST classifier showcasing dataset download + MLX-native checkpointing.
- `examples/mlx_cheetah_training.py` ‚Äì Cheetah trajectory predictor mirroring the LTC paper workflow entirely in MLX.
- `examples/enhanced_training_example.py` ‚Äì advanced training configuration with `EnhancedLTCTrainer`.
- `examples/mlx_cell_comparison.py` ‚Äì compare CTRNN, CTGRU, and ELTC cells on synthetic data.
- **Notebooks**: Interactive tutorials with visualisations (profiling, visualisation, wiring exploration).

### Datasets

- Run `bash datasets/download_datasets.sh` to mirror the UCI datasets used in the original LTC experiments into `datasets/data/`.
- The downloader also grabs Sequential MNIST (`datasets/data/smnist/mnist.npz`) and, when present on your machine, copies cheetah traces from `/Volumes/stuff/Projects/liquid_time_constant_networks/experiments_with_ltcs/data/cheetah/` into `datasets/data/cheetah/`.
- Copy the cheetah traces (`trace_*.npy`) into `datasets/data/cheetah/` (from the legacy `liquid_time_constant_networks` repository or your own captures).
- All MLX examples consume data straight from `datasets/data/‚Ä¶` and checkpoint weights under `artifacts/` using `Module.save_weights`.

---

## üõ†Ô∏è Development

### Code Quality

We use [NCPSLint](misc/emberlint.py) to maintain code quality:

\`\`\`bash
# Run linting
python misc/emberlint.py ncps/mlx

# Check for NumPy usage (prefer MLX)
python misc/emberlint.py ncps/mlx --numpy-only --verbose

# Check for unused imports
python misc/emberlint.py ncps/mlx --unused-only --verbose
\`\`\`

### Running Tests

\`\`\`bash
# Install dev dependencies
pip install -e .[dev]

# Run tests
pytest ncps/mlx/ops/tests/
\`\`\`

---

## üìä Performance

MLX delivers exceptional performance on Apple Silicon:

| Model | Backend | M1 Pro | M1 Max | M2 Ultra |
|-------|---------|--------|---------|----------|
| CfC-32 | MLX | **2.1ms** | **1.4ms** | **0.8ms** |
| CfC-32 | PyTorch | 8.3ms | 6.1ms | 4.2ms |
| LTC-64 | MLX | **3.8ms** | **2.6ms** | **1.5ms** |
| LTC-64 | PyTorch | 15.2ms | 11.3ms | 7.8ms |

*Benchmarks: Batch size 32, sequence length 100, measured on various M-series chips*

---

## üìñ Citation

If you use this code in your research, please cite both the original NCP papers and this MLX implementation:

### Original NCP Papers

\`\`\`bibtex
@article{lechner2020neural,
  title={Neural circuit policies enabling auditable autonomy},
  author={Lechner, Mathias and Hasani, Ramin and Amini, Alexander and Henzinger, Thomas A and Rus, Daniela and Grosu, Radu},
  journal={Nature Machine Intelligence},
  volume={2},
  number={10},
  pages={642--652},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{hasani2021liquid,
  title={Liquid time-constant networks},
  author={Hasani, Ramin and Lechner, Mathias and Amini, Alexander and Rus, Daniela and Grosu, Radu},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={9},
  pages={7657--7666},
  year={2021}
}

@inproceedings{hasani2023closed,
  title={Closed-form continuous-time neural networks},
  author={Hasani, Ramin and Lechner, Mathias and Amini, Alexander and Liebenwein, Lucas and Ray, Aaron and Tschaikowski, Max and Teschl, Gerald and Rus, Daniela},
  booktitle={Nature Machine Intelligence},
  year={2023}
}
\`\`\`

### This Implementation

\`\`\`bibtex
@software{ncps_mlx_2024,
  title={Neural Circuit Policies for Apple MLX},
  author={Renee, Sydney},
  year={2024},
  url={https://github.com/SolaceHarmony/ncps-mlx}
}
\`\`\`

---

## üë• Credits and Attribution

### Original Authors

This implementation is based on the groundbreaking work by:

- **[Mathias Lechner](https://github.com/mlech26l)** - Original NCP/LTC/CfC concepts and implementations
- **[Ramin Hasani](https://github.com/raminmh)** - Co-creator of Neural Circuit Policies
- **Alexander Amini** - Research contributions
- **The Liquid AI Team** - Continued development and research

### Original Repository

This is a fork and MLX port of the original ncps repository:
- **Original**: [https://github.com/mlech26l/ncps](https://github.com/mlech26l/ncps)
- **Paper**: [Neural Circuit Policies (Nature Machine Intelligence, 2020)](https://www.nature.com/articles/s42256-020-00237-3)

### MLX Port

- **MLX Implementation**: [Sydney Renee](https://github.com/SolaceHarmony)
- **Port Date**: 2024
- **MLX Framework**: [Apple ML Explore](https://github.com/ml-explore/mlx)

### Contributors

We're grateful to all contributors who have helped improve this implementation:

- Hannes Brantner
- Ka Wa Yip  
- lettercode
- shuboyang
- jm12138

And everyone who has opened issues, provided feedback, or contributed code!

---


## üéØ Roadmap

### Current Status (v2.0.0)

- ‚úÖ Core implementations (CfC, LTC, CTRNN, CT-GRU)
- ‚úÖ Bidirectional processing
- ‚úÖ Time-aware processing
- ‚úÖ MLX optimization
- ‚úÖ Comprehensive documentation
- ‚úÖ CI/CD with Apple Silicon testing

### Upcoming

- üîÑ Enhanced LTC (ELTC) improvements
- üîÑ Additional wiring patterns
- üîÑ Pre-trained models
- üîÑ PyPI package release
- üîÑ More example applications
- üîÑ Performance optimizations

### Future Goals

- üìÖ Integration with MLX training frameworks
- üìÖ Distributed training support
- üìÖ Model quantization for even faster inference
- üìÖ Visualization tools
- üìÖ Transfer learning utilities

Want to help? Check out our [CONTRIBUTING.md](CONTRIBUTING.md)!

---

## üêõ Known Issues

- ‚ö†Ô∏è ELTC has matrix dimension issues (under investigation)
- ‚ö†Ô∏è Type errors in MLX type stubs (upstream issue)

See [GitHub Issues](https://github.com/SolaceHarmony/ncps-mlx/issues) for the full list and to report new ones.


## ü§ù Contributing

Contributions are welcome! Whether it's:

- üêõ Bug reports and fixes
- ‚ú® New features or model variants
- üìö Documentation improvements
- üß™ Additional tests or examples
- üé® Performance optimizations

Please feel free to:

1. Fork the repository
2. Create a feature branch (\`git checkout -b feature/amazing-feature\`)
3. Make your changes
4. Run the linter (\`python misc/emberlint.py ncps/mlx\`)
5. Commit your changes (\`git commit -m 'Add amazing feature'\`)
6. Push to the branch (\`git push origin feature/amazing-feature\`)
7. Open a Pull Request

## üß™ Pytest & MLX Module Demo

Run `pytest` to execute a lightweight regression example that integrates the latest MLX `nn.Module` APIs. The test suite exercises `create_training_state` and `train_for_epochs` from `ncps.mlx.module_training_demo`, showing how to combine `nn.Sequential` layers, `nn.value_and_grad`, and `mlx.optimizers.Adam` in a concise training loop.

---

## üìÑ License

This project is licensed under the **Apache License 2.0** - see the [LICENSE](LICENSE) file for details.

\`\`\`
Copyright 2022 Mathias Lechner (Original ncps implementation)
Copyright 2024 Sydney Renee (MLX port)

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
\`\`\`

The Apache 2.0 license allows you to:
- ‚úÖ Use commercially
- ‚úÖ Modify
- ‚úÖ Distribute
- ‚úÖ Sublicense
- ‚úÖ Use privately

With the following conditions:
- üìã Include license and copyright notice
- üìã State changes made
- üìã Include NOTICE file if present

---

## üôè Acknowledgments

- **MIT CSAIL** for the original NCP research and development
- **Liquid AI** for continued innovation in liquid neural networks
- **Apple ML Research** for the MLX framework enabling efficient deployment on Apple Silicon
- **The open-source community** for contributions and feedback

---

## üìû Contact & Support

- **Issues**: [GitHub Issues](https://github.com/SolaceHarmony/ncps-mlx/issues)
- **Discussions**: [GitHub Discussions](https://github.com/SolaceHarmony/ncps-mlx/discussions)
- **Email**: sydney@solace.ofharmony.ai

---

## üåê Links

- **Original NCP Repo**: [mlech26l/ncps](https://github.com/mlech26l/ncps)
- **MLX Framework**: [ml-explore/mlx](https://github.com/ml-explore/mlx)
- **Liquid AI**: [liquid.ai](https://www.liquid.ai/)
- **Paper (Nature)**: [Neural Circuit Policies](https://www.nature.com/articles/s42256-020-00237-3)

---

<div align="center">

**‚≠ê Star this repo if you find it useful!**

Made with ‚ù§Ô∏è for the MLX and liquid neural network communities

</div>
